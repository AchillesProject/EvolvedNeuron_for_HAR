{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a296d2b1",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8138f95-5a02-4899-9e92-abebb9c63257",
   "metadata": {},
   "source": [
    "## Addition Problem\n",
    "Source: https://github.com/batzner/indrnn/blob/master/examples/addition_rnn.py\n",
    "\n",
    "Timesteps params: https://arxiv.org/abs/1803.04831\n",
    "\n",
    "BatchSize params: https://arxiv.org/pdf/1511.06464.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba6a7fb-fff1-4c05-8782-faf9c4179cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "from numpy import array\n",
    "\n",
    "batch_size_arr = [80, 50, 100, 180, 200]\n",
    "time_steps_arr = [100, 500, 1000, 5000, 10000, 15000]\n",
    "\n",
    "def generateAddingProblemData(batch_size, time_steps):\n",
    "    # Build the first sequence\n",
    "    add_values = np.random.rand(batch_size, time_steps)\n",
    "\n",
    "    # Build the second sequence with one 1 in each half and 0s otherwise\n",
    "    add_indices = np.zeros_like(add_values, dtype=int)\n",
    "    half = int(time_steps / 2)\n",
    "    for i in range(batch_size):\n",
    "        first_half = np.random.randint(half)\n",
    "        second_half = np.random.randint(half, time_steps)\n",
    "        add_indices[i, [first_half, second_half]] = 1\n",
    "\n",
    "    # Zip the values and indices in a third dimension:\n",
    "    # inputs has the shape (batch_size, time_steps, 2)\n",
    "    inputs = np.dstack((add_values, add_indices))\n",
    "    targets = np.sum(np.multiply(add_values, add_indices), axis=1)\n",
    "    data = np.column_stack((inputs.reshape(batch_size, time_steps*2), targets))\n",
    "    return inputs, targets, data\n",
    "\n",
    "for bs in batch_size_arr:\n",
    "    for ts in time_steps_arr:\n",
    "        _, _, addingproblemdata = (generateAddingProblemData(bs*2, ts))\n",
    "        with open(f\"../../Datasets/2_addingproblem/addingProblem.bs={bs}.ts={ts}.csv\",'w') as csvfile:\n",
    "            np.savetxt(csvfile, np.array([[2, 1]]),fmt='%d', delimiter=\",\")\n",
    "        with open(f\"../../Datasets/2_addingproblem/addingProblem.bs={bs}.ts={ts}.csv\",'a') as csvfile:\n",
    "            np.savetxt(csvfile, addingproblemdata, fmt='%.4f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523413e-5387-4cf6-98b2-9930cb0f6f7f",
   "metadata": {},
   "source": [
    "## MNIST Problem\n",
    "\n",
    "Source: https://github.com/batzner/indrnn/blob/8239a819100c40d5662f0d7440bfa7b539366b7f/examples/sequential_mnist.py#L258\n",
    "\n",
    "Hyperparams: https://arxiv.org/abs/1803.04831 and https://github.com/Sunnydreamrain/IndRNN_Theano_Lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "918ff0da-8977-40e1-b34b-acd0e74d7f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 794)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 794)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(70000, 794)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Data Dimension\n",
    "num_input = 28          # MNIST data input (image shape: 28x28)\n",
    "timesteps = 28          # Timesteps\n",
    "n_classes = 10          # Number of classes, one class per digit\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train_oh = np.zeros((y_train.shape[0], y_train.max()+1), dtype=np.float32)\n",
    "y_train_oh[np.arange(y_train.shape[0]), y_train] = 1\n",
    "y_test_oh = np.zeros((y_test.shape[0], y_test.max()+1), dtype=np.float32)\n",
    "y_test_oh[np.arange(y_test.shape[0]), y_test] = 1\n",
    "\n",
    "trainset = np.column_stack((x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]),y_train_oh))\n",
    "testset = np.column_stack((x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]),y_test_oh))\n",
    "mnist_problemdata = np.vstack((trainset, testset))\n",
    "display(trainset.shape)\n",
    "display(testset.shape)\n",
    "display(mnist_problemdata.shape)\n",
    "with open(f\"../../Datasets/3_mnist/mnist.ni={num_input}.no={n_classes}.ts={timesteps}.train={60000}.test={10000}.csv\",'w') as csvfile:\n",
    "    np.savetxt(csvfile, np.array([[num_input, n_classes]]),fmt='%d', delimiter=\",\")\n",
    "with open(f\"../../Datasets/3_mnist/mnist.ni={num_input}.no={n_classes}.ts={timesteps}.train={60000}.test={10000}.csv\",'a') as csvfile:\n",
    "    np.savetxt(csvfile, mnist_problemdata, fmt='%.4f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde44820-a48b-4a02-bd09-493dc0439958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
