{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7a300-6f9f-4e54-933b-72c208c0102a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert\" style=\"background-color:#006400; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#FFFFFF; font-size:32px'>HyperTuning for 180 Datasets</h1></div>\n",
    "\n",
    "The work is under the **\"Master Thesis\"** by **Chau Tran** with the supervision from **Prof. Roland Olsson**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7173c23-ec96-43e0-a1b8-f67ef1bb3c4c",
   "metadata": {},
   "source": [
    "## 1. Packages and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f1655e04-1989-421f-bb64-59bd00087f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kt:  1.0.2\n",
      "tf:  2.6.0\n",
      "/home/ifeai/ChauTran/git/0_HIOF_Studying/0_MasterProject\n",
      "<class 'numpy.ndarray'> (9999, 1024)\n",
      "<class 'int'> 3 <class 'int'> 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D, GlobalAveragePooling2D, Flatten, Dropout, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorboard\n",
    "import kerastuner as kt #(kt.tuners.RandomSearch, kt.tuners.Hyperband)\n",
    "from kerastuner_tensorboard_logger import (\n",
    "    TensorBoardLogger,\n",
    "    setup_tb  # Optional\n",
    ")\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "\n",
    "from functools import partial\n",
    "from matplotlib import rc, style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import pandas as pd #pd.plotting.register_matplotlib_converters\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import sys, os, math, time, datetime\n",
    "\n",
    "print(\"kt: \", kt.__version__)\n",
    "print(\"tf: \", tf.__version__)\n",
    "print(os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "style.use(\"seaborn\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale = 1)\n",
    "\n",
    "# rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Writing to file\n",
    "filepath = './Version9.128timesteps/seqnetdata.ni=3.no=5.mc=15.numTimeSteps128.version9.4.csv'\n",
    "with open(filepath, \"r\") as fp:\n",
    "    [noInput, noOutput] = [int(x) for x in fp.readline().split(',')]\n",
    "rdf = np.array(pd.read_csv(filepath, skiprows=1))\n",
    "print(type(rdf), rdf.shape)\n",
    "print(type(noInput), noInput, type(noOutput), noOutput)\n",
    "display(rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064dc2e-6869-4802-b346-30852d1a9513",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "100c9d6c-edc6-4040-af5d-783c494b0f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Separating values and labels.\n",
      "+ Training set:    (5000, 128, 3) (5000, 5) float32\n",
      "+ Validating set:  (4999, 128, 3) (4999, 5) float32\n",
      "Step 3: Normalizing the labels.\n",
      "+ Normalizied training set:    (5000, 32)\n",
      "+ Normalizied validating set:  (4999, 32)\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=1000)\n",
    "def shifting(bitlist):\n",
    "    out = 0\n",
    "    for bit in bitlist:\n",
    "        out = (out << 1) | bit\n",
    "    return out\n",
    "\n",
    "print('Step 1: Dividing the training and testing set with ratio 1:1 (50%).')\n",
    "df_val, df_train = train_test_split(rdf,test_size=0.5)\n",
    "print(df_train.shape, df_val.shape)\n",
    "\n",
    "print('Step 2: Separating values and labels.')\n",
    "# Training set\n",
    "x_train, y_train, x_val, y_val = None, None, None, None\n",
    "for i in range(df_train.shape[0]):\n",
    "    df_train_i = df_train[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "    x_train_i, y_train_i = df_train_i[:, 0:noInput], df_train_i[-1, noInput:]\n",
    "    x_train = x_train_i[np.newaxis,:,:] if x_train is None else np.append(x_train, x_train_i[np.newaxis,:,:], axis=0)\n",
    "    y_train = y_train_i.reshape(1, -1) if y_train is None else np.append(y_train, y_train_i.reshape(1, -1), axis=0)\n",
    "print(\"+ Training set:   \", x_train.shape, y_train.shape, x_train.dtype)\n",
    "\n",
    "# Validating set\n",
    "x_test, y_test = None, None\n",
    "for i in range(df_val.shape[0]):\n",
    "    df_val_i = df_val[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "    x_val_i, y_val_i = df_val_i[:, 0:noInput], df_val_i[-1, noInput:]\n",
    "    x_val = x_val_i[np.newaxis,:,:] if x_val is None else np.append(x_val, x_val_i[np.newaxis,:,:], axis=0)\n",
    "    y_val = y_val_i.reshape(1,-1) if y_val is None else np.append(y_val, y_val_i.reshape(1,-1), axis=0)\n",
    "print(\"+ Validating set: \", x_val.shape, y_val.shape, x_val.dtype)\n",
    "\n",
    "print('Step 3: Normalizing the labels.')\n",
    "# Training set\n",
    "y_train_norm = []\n",
    "for i in range(y_train.shape[0]):\n",
    "    y_train_norm.append(shifting(y_train[i,:].astype('int32')))\n",
    "    \n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(np.array(y_train_norm).reshape(-1, 1))\n",
    "y_train_norm = enc.transform(np.array(y_train_norm).reshape(-1, 1))\n",
    "print(\"+ Normalizied training set:   \", y_train_norm.shape)\n",
    "# Validating set\n",
    "y_val_norm = []\n",
    "for i in range(y_val.shape[0]):\n",
    "    y_val_norm.append(shifting(y_val[i,:].astype('int32')))\n",
    "    \n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(np.array(y_val_norm).reshape(-1, 1))\n",
    "y_val_norm = enc.transform(np.array(y_val_norm).reshape(-1, 1))\n",
    "print(\"+ Normalizied validating set: \", y_val_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01e021-bf79-4c1d-ac30-18bd79f180a4",
   "metadata": {},
   "source": [
    "## 3. LSTM Model with original outputs (5 bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "88451003-9a3e-4dbc-bcd6-a660d5924c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2828 - binary_accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "# with strategy.scope(): \n",
    "lstm_model = tf.keras.Sequential()\n",
    "lstm_model.add(\n",
    "  tf.keras.layers.LSTM(\n",
    "      units=128, \n",
    "      input_shape=[x_train.shape[1], x_train.shape[2]],\n",
    "      activation='tanh', recurrent_activation='sigmoid',\n",
    "      unroll =False,\n",
    "      use_bias=True,\n",
    "      recurrent_dropout=0,\n",
    "      return_sequences=False\n",
    "  )\n",
    ")\n",
    "\n",
    "lstm_model.add(tf.keras.layers.Dense(y_train.shape[1], activation='tanh'))\n",
    "adam = tf.optimizers.Adam(learning_rate = 0.001, decay=1e-6)\n",
    "# lstm_model.compile(loss='mse', optimizer=adam, metrics='mse')\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.51)])\n",
    "\n",
    "strt_time = datetime.datetime.now() \n",
    "lstm_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=8,\n",
    "    batch_size=1,\n",
    "    verbose=0,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "curr_time = datetime.datetime.now()\n",
    "display(lstm_model.summary())\n",
    "timedelta = curr_time - strt_time\n",
    "dnn_train_time = timedelta.total_seconds()\n",
    "\n",
    "val_performance = lstm_model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6f9e987f-40e2-4800-90b1-f471dcab3f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19788855  0.6051079  -0.5205557   0.99930775  0.5333794 ]\n",
      " [ 0.99878234  0.50712156 -0.7296089   0.99404347  0.5857842 ]\n",
      " [ 0.99945194  0.44372046  0.99650085  0.99919295  0.55372477]\n",
      " ...\n",
      " [ 0.9923825   0.48660094  0.99015915  0.99815124  0.5038921 ]\n",
      " [-0.68550926  0.585049    0.9999517  -0.9407191   0.38284588]\n",
      " [ 0.9945059   0.48318762  0.98883027  0.99833316  0.50074506]]\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 0.035007001400280055 0.8030405640602112 4014.3997797369957\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm_model.predict(x_val, verbose=0)\n",
    "print(y_pred)\n",
    "\n",
    "m = tf.keras.metrics.BinaryAccuracy()\n",
    "m.update_state(y_pred, y_val)\n",
    "print(m.result().numpy())\n",
    "\n",
    "y_pred[np.where(y_pred < 0)] = 0\n",
    "y_pred[np.where(y_pred >= 0)] = 1\n",
    "display(y_pred.astype('int32'))\n",
    "display(y_val.astype('int32'))\n",
    "count = 0\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if (np.array_equal(y_pred[i].astype('int32'), y_val[i].astype('int32'))):\n",
    "        count += 1\n",
    "print(count, count/y_pred.shape[0], val_performance[1], val_performance[1]*y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65120811-fa64-4842-920f-4889b7ca920e",
   "metadata": {},
   "source": [
    "## 3. LSTM Model with normalized outputs (32 bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8bb31b67-5735-48ad-82df-3c22067abbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_49 (LSTM)               (None, 8)                 384       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                288       \n",
      "=================================================================\n",
      "Total params: 672\n",
      "Trainable params: 672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0298 - categorical_accuracy: 0.0548\n"
     ]
    }
   ],
   "source": [
    "# with strategy.scope(): \n",
    "lstm_model = tf.keras.Sequential()\n",
    "lstm_model.add(\n",
    "  tf.keras.layers.LSTM(\n",
    "      units=8, \n",
    "      input_shape=[x_train.shape[1], x_train.shape[2]],\n",
    "      activation='tanh', recurrent_activation='sigmoid',\n",
    "      return_sequences=False #many2many\n",
    "  )\n",
    ")\n",
    "lstm_model.add(tf.keras.layers.Dense(y_train_norm.shape[1], activation='tanh'))\n",
    "adam = tf.optimizers.Adam(learning_rate = 0.001, decay=1e-6)\n",
    "lstm_model.compile(loss='mse', optimizer=adam, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "strt_time = datetime.datetime.now() \n",
    "lstm_model.fit(\n",
    "    x_train, y_train_norm,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    verbose=0,\n",
    "    validation_data=(x_val, y_val_norm),\n",
    "    shuffle=True,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "curr_time = datetime.datetime.now()\n",
    "display(lstm_model.summary())\n",
    "timedelta = curr_time - strt_time\n",
    "dnn_train_time = timedelta.total_seconds()\n",
    "\n",
    "val_performance = lstm_model.evaluate(x_val, y_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "908662f1-1844-40c2-bcd8-e90f9f3d67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054810964 274.00000689178705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.9581209e-05, -4.1223639e-03,  1.0322663e-03, ...,\n",
       "         6.5011114e-02,  6.1142743e-02,  5.7384141e-02],\n",
       "       [ 2.9469490e-02,  1.2287834e-02,  2.7728166e-02, ...,\n",
       "         4.1147072e-02,  4.6307910e-02,  3.7659619e-02],\n",
       "       [ 2.4722844e-02,  2.3733180e-02,  2.1713689e-02, ...,\n",
       "         4.9571559e-02,  4.8341978e-02,  2.8172469e-02],\n",
       "       ...,\n",
       "       [ 2.3851139e-02,  1.4238188e-02,  2.3083949e-02, ...,\n",
       "         3.9092626e-02,  5.2784853e-02,  3.0109696e-02],\n",
       "       [ 2.2479740e-03, -8.3094891e-03,  4.3173889e-03, ...,\n",
       "         6.3332014e-02,  5.9263784e-02,  6.2414411e-02],\n",
       "       [-4.6912581e-05, -8.2772933e-03,  3.1036984e-03, ...,\n",
       "         6.7349046e-02,  5.7406075e-02,  6.8269171e-02]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=274.0>, <tf.Variable 'count:0' shape=() dtype=float32, numpy=4999.0>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.0018003600720144029 [0.0298045352101326, 0.054810963571071625]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm_model.predict(x_val, verbose=0)\n",
    "m = tf.keras.metrics.CategoricalAccuracy()\n",
    "m.update_state(y_pred, y_val_norm)\n",
    "print(m.result().numpy(), m.result().numpy()*y_pred.shape[0])\n",
    "display(y_pred)\n",
    "print(m.variables)\n",
    "y_pred[np.where(y_pred <= 0.0505)] = 0\n",
    "y_pred[np.where(y_pred > 0.0505)] = 1\n",
    "display(y_pred.astype('int32'))\n",
    "display(y_val_norm.astype('int32'))\n",
    "count = 0\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if (np.array_equal(y_pred[i].astype('int32'), y_val_norm[i].astype('int32'))):\n",
    "        count += 1\n",
    "print(count, count/y_pred.shape[0], val_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28897b-33c7-41d4-bc22-47efd1b7f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
