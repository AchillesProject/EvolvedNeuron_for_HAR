{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7a300-6f9f-4e54-933b-72c208c0102a",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#006400; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#FFFFFF; font-size:32px'>HyperTuning for 180 Datasets</h1></div>\n",
    "\n",
    "The work is under the **\"Master Thesis\"** by **Chau Tran** with the supervision from **Prof. Roland Osslen**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7173c23-ec96-43e0-a1b8-f67ef1bb3c4c",
   "metadata": {},
   "source": [
    "## 1. Packages and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1655e04-1989-421f-bb64-59bd00087f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kt:  1.0.2\n",
      "tf:  2.6.0\n",
      "/home/ifeai/ChauTran/git/0_HIOF_Studying/0_MasterProject\n",
      "<class 'numpy.ndarray'> (9999, 1024)\n",
      "<class 'int'> 3 <class 'int'> 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 1, 0, 1],\n",
       "       [1, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 0, 1, ..., 0, 1, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D, GlobalAveragePooling2D, Flatten, Dropout, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorboard\n",
    "import kerastuner as kt #(kt.tuners.RandomSearch, kt.tuners.Hyperband)\n",
    "from kerastuner_tensorboard_logger import (\n",
    "    TensorBoardLogger,\n",
    "    setup_tb  # Optional\n",
    ")\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "\n",
    "from functools import partial\n",
    "from matplotlib import rc, style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import pandas as pd #pd.plotting.register_matplotlib_converters\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import sys, os, math, time, datetime\n",
    "\n",
    "print(\"kt: \", kt.__version__)\n",
    "print(\"tf: \", tf.__version__)\n",
    "print(os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "style.use(\"seaborn\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale = 1)\n",
    "\n",
    "# rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Writing to file\n",
    "filepath = './Version9.128timesteps/seqnetdata.ni=3.no=5.mc=15.numTimeSteps128.version9.0.csv'\n",
    "with open(filepath, \"r\") as fp:\n",
    "    [noInput, noOutput] = [int(x) for x in fp.readline().split(',')]\n",
    "rdf = np.array(pd.read_csv(filepath, skiprows=1))\n",
    "print(type(rdf), rdf.shape)\n",
    "print(type(noInput), noInput, type(noOutput), noOutput)\n",
    "display(rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064dc2e-6869-4802-b346-30852d1a9513",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a55edc2-8896-4a4e-93b4-52161bdf78f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Formatting the training and testing sets and generating validating set.\n",
      "Training set:  (5000, 118, 3) (5000, 118, 5)\n",
      "Validating set:  (5000, 10, 3) (5000, 10, 5)\n",
      "Testing set:  (4999, 128, 3) (4999, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=1000)\n",
    "print('Step 1: Dividing the training and testing set with ratio 1:1 (50%).')\n",
    "df_test, df_train = train_test_split(rdf,test_size=0.5)\n",
    "print(df_train.shape, df_test.shape)\n",
    "\n",
    "print('Step 2: Formatting the training and testing sets and generating validating set.')\n",
    "# Training and Validating sets\n",
    "x_train, y_train, x_val, y_val = None, None, None, None\n",
    "for i in range(df_train.shape[0]):\n",
    "    df_train_i = df_train[i].reshape(-1, noInput+noOutput)\n",
    "    x_train_i, y_train_i = df_train_i[:, 0:noInput], df_train_i[:, noInput:]\n",
    "    x_train_i, x_val_i = train_test_split(x_train_i, test_size=0.078125)\n",
    "    y_train_i, y_val_i = train_test_split(y_train_i, test_size=0.078125)\n",
    "    x_train = x_train_i[np.newaxis,:,:] if x_train is None else np.append(x_train, x_train_i[np.newaxis,:,:], axis=0)\n",
    "    y_train = y_train_i[np.newaxis,:,:] if y_train is None else np.append(y_train, y_train_i[np.newaxis,:,:], axis=0)\n",
    "    x_val   = x_val_i[np.newaxis,:,:]   if x_val   is None else np.append(x_val, x_val_i[np.newaxis,:,:], axis=0)\n",
    "    y_val   = y_val_i[np.newaxis,:,:]   if y_val   is None else np.append(y_val, y_val_i[np.newaxis,:,:], axis=0)\n",
    "print(\"Training set: \", x_train.shape, y_train.shape)\n",
    "print(\"Validating set: \", x_val.shape, y_val.shape)\n",
    "\n",
    "#Testing set\n",
    "x_test, y_test = None, None\n",
    "for i in range(df_test.shape[0]):\n",
    "    df_test_i = df_test[i].reshape(-1, noInput+noOutput)\n",
    "    x_test_i, y_test_i = df_test_i[:, 0:noInput], df_test_i[:, noInput:]\n",
    "    x_test = x_test_i[np.newaxis,:,:] if x_test is None else np.append(x_test, x_test_i[np.newaxis,:,:], axis=0)\n",
    "    y_test = y_test_i[np.newaxis,:,:] if y_test is None else np.append(y_test, y_test_i[np.newaxis,:,:], axis=0)\n",
    "print(\"Testing set: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01e021-bf79-4c1d-ac30-18bd79f180a4",
   "metadata": {},
   "source": [
    "## 3. LSTM with HyperBand (for Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb31b67-5735-48ad-82df-3c22067abbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4bf42-2c11-4be8-88b9-517da4a72b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a14ee-eb98-4792-a360-dcb92f46367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir_lstm_v1 = \"logs//hparams//lstm//v1_\" + snapshot\n",
    "activationfunctions = ['relu', 'sigmoid', 'tanh', 'softmax', 'softsign', 'selu', 'elu']\n",
    "def tunner_lstm_model_v1(hp):\n",
    "    \"\"\"Builds a recurrent model.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(Input(shape=(rows, cols)))\n",
    "    model.add(LSTM(units=hp.Int('units_LSTM',\n",
    "                                min_value=2,\n",
    "                                max_value=512,\n",
    "                                step=32), \n",
    "                   activation=hp.Choice('activation_LSTM', activationfunctions)))\n",
    "    model.add(Dense(units=hp.Int('units_hidden',\n",
    "                                min_value=2,\n",
    "                                max_value=256,\n",
    "                                step=2),\n",
    "                   activation='relu'))\n",
    "    \n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    if (hp.Choice('optimizer', ['adam', 'sgd']) == 'adam'):\n",
    "        optimizer = keras.optimizers.Adam(hp.Choice('learning_rate',\n",
    "                                  values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5]))\n",
    "    else:\n",
    "        optimizer = keras.optimizers.SGD(hp.Choice('learning_rate',\n",
    "                                  values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5]))\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "                           tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')\n",
    "                          ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm_tuner_v1=Hyperband(\n",
    "    tunner_lstm_model_v1,\n",
    "    objective=kt.Objective('val_categorical_accuracy', direction='max'),\n",
    "    max_epochs=50,\n",
    "    seed=42,\n",
    "    directory=\"logs/tuner/lstm\",\n",
    "    project_name=\"MasterThesis\",\n",
    "    overwrite=True,\n",
    "    logger=TensorBoardLogger(\n",
    "        metrics=['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy', 'precision', 'recall'], logdir=log_dir_lstm_v1,\n",
    "    ) # add only this argument\n",
    ")\n",
    "\n",
    "setup_tb(lstm_tuner_v1)  # (Optional) For more accurate visualization.\n",
    "lstm_tuner_v1.search(X_train, y_train,\n",
    "             epochs=50,\n",
    "             batch_size=64,\n",
    "             validation_data=(X_val, y_val),\n",
    "             shuffle=False\n",
    "            )\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir_lstm_v1, profile_batch = '500,520')\n",
    "bestparams_v1 = lstm_tuner_v1.get_best_hyperparameters(1)[0]\n",
    "hyper_model_v1 = lstm_tuner_v1.hypermodel.build(bestparams_v1)\n",
    "training_history_v1 = hyper_model_v1.fit(\n",
    "    X_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=64,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=40,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")\n",
    "print(\"Average loss: \", np.average(training_history_v1.history['loss']))\n",
    "print(\"Average val loss: \", np.average(training_history_v1.history['val_loss']))\n",
    "print(\"Average accuracy: \", np.average(training_history_v1.history['categorical_accuracy']))\n",
    "print(\"Average val accuracy: \", np.average(training_history_v1.history['val_categorical_accuracy']))\n",
    "train_result = hyper_model_v1.evaluate(X_train, y_train)\n",
    "val_result = hyper_model_v1.evaluate(X_val, y_val)\n",
    "test_result = hyper_model_v1.evaluate(X_test, y_test)\n",
    "newUser_result = hyper_model_v1.evaluate(X_newUser, y_newUser)\n",
    "print(\"Train: \", train_result)\n",
    "print(\"Train: \", val_result)\n",
    "print(\"Train: \", test_result)\n",
    "print(\"Train: \", newUser_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec1605-3f74-4008-a789-07b0c598f912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py385_gpu",
   "language": "python",
   "name": "py385_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
