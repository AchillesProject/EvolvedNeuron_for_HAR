{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7a300-6f9f-4e54-933b-72c208c0102a",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#006400; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#FFFFFF; font-size:32px'>HyperTuning for 180 Datasets</h1></div>\n",
    "\n",
    "The work is under the **\"Master Thesis\"** by **Chau Tran** with the supervision from **Prof. Roland Olsson**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7173c23-ec96-43e0-a1b8-f67ef1bb3c4c",
   "metadata": {},
   "source": [
    "## 1. Packages and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1655e04-1989-421f-bb64-59bd00087f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kt:  1.0.2\n",
      "tf:  2.6.0\n",
      "/home/ifeai/ChauTran/git/0_HIOF_Studying/0_MasterProject\n",
      "<class 'numpy.ndarray'> (9999, 1024)\n",
      "<class 'int'> 3 <class 'int'> 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 1, 0, 1],\n",
       "       [1, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 0, 1, ..., 0, 1, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D, GlobalAveragePooling2D, Flatten, Dropout, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorboard\n",
    "import kerastuner as kt #(kt.tuners.RandomSearch, kt.tuners.Hyperband)\n",
    "from kerastuner_tensorboard_logger import (\n",
    "    TensorBoardLogger,\n",
    "    setup_tb  # Optional\n",
    ")\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "\n",
    "from functools import partial\n",
    "from matplotlib import rc, style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import pandas as pd #pd.plotting.register_matplotlib_converters\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import sys, os, math, time, datetime\n",
    "\n",
    "print(\"kt: \", kt.__version__)\n",
    "print(\"tf: \", tf.__version__)\n",
    "print(os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "style.use(\"seaborn\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale = 1)\n",
    "\n",
    "# rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Writing to file\n",
    "filepath = './Version9.128timesteps/seqnetdata.ni=3.no=5.mc=15.numTimeSteps128.version9.0.csv'\n",
    "with open(filepath, \"r\") as fp:\n",
    "    [noInput, noOutput] = [int(x) for x in fp.readline().split(',')]\n",
    "rdf = np.array(pd.read_csv(filepath, skiprows=1))\n",
    "print(type(rdf), rdf.shape)\n",
    "print(type(noInput), noInput, type(noOutput), noOutput)\n",
    "display(rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064dc2e-6869-4802-b346-30852d1a9513",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "100c9d6c-edc6-4040-af5d-783c494b0f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Formatting the training and testing sets and generating validating set.\n",
      "Training set:  (5000, 128, 3) (5000, 128, 5) float32\n",
      "Testing set:  (4999, 128, 3) (4999, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=1000)\n",
    "print('Step 1: Dividing the training and testing set with ratio 1:1 (50%).')\n",
    "df_test, df_train = train_test_split(rdf,test_size=0.5)\n",
    "print(df_train.shape, df_test.shape)\n",
    "\n",
    "print('Step 2: Formatting the training and testing sets and generating validating set.')\n",
    "# Training and Validating sets\n",
    "x_train, y_train, x_val, y_val = None, None, None, None\n",
    "for i in range(df_train.shape[0]):\n",
    "    df_train_i = df_train[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "    x_train_i, y_train_i = df_train_i[:, 0:noInput], df_train_i[:, noInput:]\n",
    "#     x_train_i, x_val_i = train_test_split(x_train_i, test_size=0.078125)\n",
    "#     y_train_i, y_val_i = train_test_split(y_train_i, test_size=0.078125)\n",
    "    x_train = x_train_i[np.newaxis,:,:] if x_train is None else np.append(x_train, x_train_i[np.newaxis,:,:], axis=0)\n",
    "    y_train = y_train_i[np.newaxis,:,:] if y_train is None else np.append(y_train, y_train_i[np.newaxis,:,:], axis=0)\n",
    "#     x_val   = x_val_i[np.newaxis,:,:]   if x_val   is None else np.append(x_val, x_val_i[np.newaxis,:,:], axis=0)\n",
    "#     y_val   = y_val_i[np.newaxis,:,:]   if y_val   is None else np.append(y_val, y_val_i[np.newaxis,:,:], axis=0)\n",
    "print(\"Training set: \", x_train.shape, y_train.shape, x_train.dtype)\n",
    "# print(\"Validating set: \", x_val.shape, y_val.shape)\n",
    "\n",
    "#Testing set\n",
    "x_test, y_test = None, None\n",
    "for i in range(df_test.shape[0]):\n",
    "    df_test_i = df_test[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "    x_test_i, y_test_i = df_test_i[:, 0:noInput], df_test_i[:, noInput:]\n",
    "    x_test = x_test_i[np.newaxis,:,:] if x_test is None else np.append(x_test, x_test_i[np.newaxis,:,:], axis=0)\n",
    "    y_test = y_test_i[np.newaxis,:,:] if y_test is None else np.append(y_test, y_test_i[np.newaxis,:,:], axis=0)\n",
    "print(\"Testing set: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01e021-bf79-4c1d-ac30-18bd79f180a4",
   "metadata": {},
   "source": [
    "## 3. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bb31b67-5735-48ad-82df-3c22067abbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/losses.py:1204 mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10514 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 128 and 5 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_18/dense_37/Softmax, IteratorGetNext:1)' with input shapes: [?,128], [?,128,5].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-970c6a4f9ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mstrt_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m lstm_model.fit(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/losses.py:1204 mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10514 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/ifeai/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 128 and 5 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_18/dense_37/Softmax, IteratorGetNext:1)' with input shapes: [?,128], [?,128,5].\n"
     ]
    }
   ],
   "source": [
    "# with strategy.scope(): \n",
    "lstm_model = tf.keras.Sequential()\n",
    "lstm_model.add(\n",
    "    tf.keras.layers.Bidirectional(\n",
    "      tf.keras.layers.LSTM(\n",
    "          units=128, \n",
    "          input_shape=[x_train.shape[1], x_train.shape[2]],\n",
    "          activation='tanh', recurrent_activation='sigmoid',\n",
    "          return_sequences=False\n",
    "      )\n",
    "    )\n",
    ")\n",
    "lstm_model.add(tf.keras.layers.Dropout(rate=0.5))\n",
    "lstm_model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "lstm_model.add(tf.keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "adam = tf.optimizers.Adam(learning_rate = 0.001, decay=1e-6)\n",
    "lstm_model.compile(loss='mse', optimizer=adam, metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "strt_time = datetime.datetime.now() \n",
    "lstm_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_split=0.078125,\n",
    "    shuffle=True,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "curr_time = datetime.datetime.now()\n",
    "display(lstm_model.summary())\n",
    "timedelta = curr_time - strt_time\n",
    "dnn_train_time = timedelta.total_seconds()\n",
    "\n",
    "val_performance = lstm_model.evaluate(x_val, y_val)\n",
    "performance = lstm_model.predict(x_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9a14ee-eb98-4792-a360-dcb92f46367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir_lstm_v1 = \"logs//hparams//lstm//v1_\" + snapshot\n",
    "# activationfunctions = ['relu', 'sigmoid', 'tanh', 'softmax', 'softsign', 'selu', 'elu']\n",
    "# def tunner_lstm_model_v1(hp):\n",
    "#     \"\"\"Builds a recurrent model.\"\"\"\n",
    "#     model = keras.Sequential()\n",
    "#     model.add(Input(shape=(rows, cols)))\n",
    "#     model.add(LSTM(units=hp.Int('units_LSTM',\n",
    "#                                 min_value=2,\n",
    "#                                 max_value=512,\n",
    "#                                 step=32), \n",
    "#                    activation=hp.Choice('activation_LSTM', activationfunctions)))\n",
    "#     model.add(Dense(units=hp.Int('units_hidden',\n",
    "#                                 min_value=2,\n",
    "#                                 max_value=256,\n",
    "#                                 step=2),\n",
    "#                    activation='relu'))\n",
    "    \n",
    "#     model.add(Dense(6, activation='softmax'))\n",
    "#     if (hp.Choice('optimizer', ['adam', 'sgd']) == 'adam'):\n",
    "#         optimizer = keras.optimizers.Adam(hp.Choice('learning_rate',\n",
    "#                                   values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5]))\n",
    "#     else:\n",
    "#         optimizer = keras.optimizers.SGD(hp.Choice('learning_rate',\n",
    "#                                   values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5]))\n",
    "#     model.compile(optimizer=optimizer,\n",
    "#                   loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#                   metrics=[tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "#                            tf.keras.metrics.Precision(name='precision'),\n",
    "#                            tf.keras.metrics.Recall(name='recall')\n",
    "#                           ])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# lstm_tuner_v1=Hyperband(\n",
    "#     tunner_lstm_model_v1,\n",
    "#     objective=kt.Objective('val_categorical_accuracy', direction='max'),\n",
    "#     max_epochs=50,\n",
    "#     seed=42,\n",
    "#     directory=\"logs/tuner/lstm\",\n",
    "#     project_name=\"MasterThesis\",\n",
    "#     overwrite=True,\n",
    "#     logger=TensorBoardLogger(\n",
    "#         metrics=['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy', 'precision', 'recall'], logdir=log_dir_lstm_v1,\n",
    "#     ) # add only this argument\n",
    "# )\n",
    "\n",
    "# setup_tb(lstm_tuner_v1)  # (Optional) For more accurate visualization.\n",
    "# lstm_tuner_v1.search(X_train, y_train,\n",
    "#              epochs=50,\n",
    "#              batch_size=64,\n",
    "#              validation_data=(X_val, y_val),\n",
    "#              shuffle=False\n",
    "#             )\n",
    "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir_lstm_v1, profile_batch = '500,520')\n",
    "# bestparams_v1 = lstm_tuner_v1.get_best_hyperparameters(1)[0]\n",
    "# hyper_model_v1 = lstm_tuner_v1.hypermodel.build(bestparams_v1)\n",
    "# training_history_v1 = hyper_model_v1.fit(\n",
    "#     X_train, # input\n",
    "#     y_train, # output\n",
    "#     batch_size=64,\n",
    "#     verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "#     epochs=40,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     callbacks=[tensorboard_callback],\n",
    "# )\n",
    "# print(\"Average loss: \", np.average(training_history_v1.history['loss']))\n",
    "# print(\"Average val loss: \", np.average(training_history_v1.history['val_loss']))\n",
    "# print(\"Average accuracy: \", np.average(training_history_v1.history['categorical_accuracy']))\n",
    "# print(\"Average val accuracy: \", np.average(training_history_v1.history['val_categorical_accuracy']))\n",
    "# train_result = hyper_model_v1.evaluate(X_train, y_train)\n",
    "# val_result = hyper_model_v1.evaluate(X_val, y_val)\n",
    "# test_result = hyper_model_v1.evaluate(X_test, y_test)\n",
    "# newUser_result = hyper_model_v1.evaluate(X_newUser, y_newUser)\n",
    "# print(\"Train: \", train_result)\n",
    "# print(\"Train: \", val_result)\n",
    "# print(\"Train: \", test_result)\n",
    "# print(\"Train: \", newUser_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py385_gpu",
   "language": "python",
   "name": "py385_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
