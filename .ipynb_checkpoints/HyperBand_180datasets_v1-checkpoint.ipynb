{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7a300-6f9f-4e54-933b-72c208c0102a",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#006400; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#FFFFFF; font-size:32px'>HyperTuning for 180 Datasets</h1></div>\n",
    "\n",
    "The work is under the **\"Master Thesis\"** by **Chau Tran** with the supervision from **Prof. Roland Olsson**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7173c23-ec96-43e0-a1b8-f67ef1bb3c4c",
   "metadata": {},
   "source": [
    "## 1. Packages and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1655e04-1989-421f-bb64-59bd00087f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kt:  1.0.2\n",
      "tf:  2.6.0\n",
      "/home/ifeai/ChauTran/git/0_HIOF_Studying/0_MasterProject\n",
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Separating values and labels.\n",
      "+ Training set:    (5000, 128, 3) (5000, 5) float32\n",
      "+ Validating set:  (4999, 128, 3) (4999, 5) float32\n",
      "Step 3: LSTM modeling.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 0.7318 - binary_accuracy: 0.9522\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7282 - binary_accuracy: 0.9528\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 7ms/step - loss: 0.7282 - binary_accuracy: 0.9528\n",
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Separating values and labels.\n",
      "+ Training set:    (5000, 128, 3) (5000, 5) float32\n",
      "+ Validating set:  (4999, 128, 3) (4999, 5) float32\n",
      "Step 3: LSTM modeling.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 6.9766 - binary_accuracy: 0.5477\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 6.9766 - binary_accuracy: 0.5477\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step - loss: 6.9766 - binary_accuracy: 0.5477\n",
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Separating values and labels.\n",
      "+ Training set:    (5000, 128, 3) (5000, 5) float32\n",
      "+ Validating set:  (4999, 128, 3) (4999, 5) float32\n",
      "Step 3: LSTM modeling.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 2.0963 - binary_accuracy: 0.5585\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6571 - binary_accuracy: 0.6141\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7114 - binary_accuracy: 0.6211\n",
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Separating values and labels.\n",
      "+ Training set:    (5000, 128, 3) (5000, 5) float32\n",
      "+ Validating set:  (4999, 128, 3) (4999, 5) float32\n",
      "Step 3: LSTM modeling.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3408 - binary_accuracy: 0.8540\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0932 - binary_accuracy: 0.9904\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0105 - binary_accuracy: 0.9990\n",
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Separating values and labels.\n",
      "+ Training set:    (5000, 128, 3) (5000, 5) float32\n",
      "+ Validating set:  (4999, 128, 3) (4999, 5) float32\n",
      "Step 3: LSTM modeling.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D, GlobalAveragePooling2D, Flatten, Dropout, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorboard\n",
    "import kerastuner as kt #(kt.tuners.RandomSearch, kt.tuners.Hyperband)\n",
    "from kerastuner_tensorboard_logger import (\n",
    "    TensorBoardLogger,\n",
    "    setup_tb  # Optional\n",
    ")\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "\n",
    "from functools import partial\n",
    "from matplotlib import rc, style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import pandas as pd #pd.plotting.register_matplotlib_converters\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import sys, os, math, time, datetime\n",
    "\n",
    "print(\"kt: \", kt.__version__)\n",
    "print(\"tf: \", tf.__version__)\n",
    "print(os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "style.use(\"seaborn\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale = 1)\n",
    "\n",
    "# rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def seperateValues(data):\n",
    "    x_data, y_data = None, None\n",
    "    for i in range(data.shape[0]):\n",
    "        x_data_i = data[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "        x_data_i, y_data_i = x_data_i[:, 0:noInput], x_data_i[-1, noInput:]\n",
    "        x_data = x_data_i[np.newaxis,:,:] if x_data is None else np.append(x_data, x_data_i[np.newaxis,:,:], axis=0)\n",
    "        y_data = y_data_i.reshape(1, -1) if y_data is None else np.append(y_data, y_data_i.reshape(1, -1), axis=0)\n",
    "    return x_data, y_data\n",
    "\n",
    "path = './Version9.128timesteps'\n",
    "fileslist = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "val_performance, train_time = {}, {}\n",
    "FILESNUMBER = 10\n",
    "LSTMNUMBER  = 3\n",
    "loss_method = 'binary_crossentropy'\n",
    "for i in range(FILESNUMBER):\n",
    "    # Getting data from csv file\n",
    "    filepath = join(path,fileslist[i])\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        [noInput, noOutput] = [int(x) for x in fp.readline().split(',')]\n",
    "    rdf = np.array(pd.read_csv(filepath, skiprows=1))\n",
    "\n",
    "    print('Step 1: Dividing the training and testing set with ratio 1:1 (50%).')\n",
    "    df_val, df_train = train_test_split(rdf,test_size=0.5)\n",
    "    print(df_train.shape, df_val.shape)\n",
    "\n",
    "    print('Step 2: Separating values and labels.')\n",
    "    x_train, y_train = seperateValues(df_train)\n",
    "    x_val, y_val = seperateValues(df_val)\n",
    "    print(\"+ Training set:   \", x_train.shape, y_train.shape, x_train.dtype)\n",
    "    print(\"+ Validating set: \", x_val.shape, y_val.shape, x_val.dtype)\n",
    "    \n",
    "    print('Step 3: LSTM modeling.')\n",
    "    lstm_model = tf.keras.Sequential()\n",
    "    lstm_model.add(\n",
    "      tf.keras.layers.LSTM(\n",
    "          units=128, \n",
    "          input_shape=[x_train.shape[1], x_train.shape[2]],\n",
    "          activation='tanh', recurrent_activation='sigmoid',\n",
    "          unroll =False,\n",
    "          use_bias=True,\n",
    "          recurrent_dropout=0,\n",
    "          return_sequences=False\n",
    "      )\n",
    "    )\n",
    "    lstm_model.add(tf.keras.layers.Dense(y_train.shape[1], activation='tanh'))\n",
    "    adam = tf.optimizers.Adam(learning_rate = 0.001, decay=1e-6)\n",
    "    lstm_model.compile(loss=loss_method, optimizer=adam, metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.51)])\n",
    "    val_performance[fileslist[i].split('.')[6]] = []\n",
    "    train_time[fileslist[i].split('.')[6]] = []\n",
    "    for lstm_no in range(LSTMNUMBER):\n",
    "        strt_time = datetime.datetime.now() \n",
    "        lstm_model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=8,\n",
    "            batch_size=1,\n",
    "            verbose=0,\n",
    "            validation_data=(x_val, y_val),\n",
    "            shuffle=True,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        curr_time = datetime.datetime.now()\n",
    "        display(lstm_model.summary())\n",
    "        timedelta = curr_time - strt_time\n",
    "        train_time[fileslist[i].split('.')[6]].append(timedelta.total_seconds())\n",
    "        val_performance[fileslist[i].split('.')[6]].append(lstm_model.evaluate(x_val, y_val))\n",
    "df = (pd.DataFrame.from_dict(val_performance, orient='index'))\n",
    "df[0] = df.apply(lambda x: round(x[0][1], 5),axis=1)\n",
    "df[1] = df.apply(lambda x: round(x[1][1], 5),axis=1)\n",
    "df[2] = df.apply(lambda x: round(x[2][1], 5),axis=1)\n",
    "df = pd.concat([df, pd.DataFrame.from_dict(train_time, orient='index').rename(columns = {0: 'Training_Time'})], axis=1)\n",
    "df = df.rename(columns={0: '1st_run', 1: '2nd_run', 2: '3rd_run'})\n",
    "df.to_csv('./Results/{}_10datasets.csv'.format(loss_method), index=True, index_label='Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fd781662-4794-4ece-9cfa-2b3a1b0cf0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D, GlobalAveragePooling2D, Flatten, Dropout, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorboard\n",
    "import kerastuner as kt #(kt.tuners.RandomSearch, kt.tuners.Hyperband)\n",
    "from kerastuner_tensorboard_logger import (\n",
    "    TensorBoardLogger,\n",
    "    setup_tb  # Optional\n",
    ")\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "\n",
    "from functools import partial\n",
    "from matplotlib import rc, style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import pandas as pd #pd.plotting.register_matplotlib_converters\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import sys, os, math, time, datetime\n",
    "\n",
    "print(\"kt: \", kt.__version__)\n",
    "print(\"tf: \", tf.__version__)\n",
    "print(os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "style.use(\"seaborn\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale = 1)\n",
    "\n",
    "# rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def seperateValues(data):\n",
    "    x_data, y_data = None, None\n",
    "    for i in range(data.shape[0]):\n",
    "        x_data_i = data[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "        x_data_i, y_data_i = x_data_i[:, 0:noInput], x_data_i[-1, noInput:]\n",
    "        x_data = x_data_i[np.newaxis,:,:] if x_data is None else np.append(x_data, x_data_i[np.newaxis,:,:], axis=0)\n",
    "        y_data = y_data_i.reshape(1, -1) if y_data is None else np.append(y_data, y_data_i.reshape(1, -1), axis=0)\n",
    "    return x_data, y_data\n",
    "\n",
    "path = './Version9.128timesteps'\n",
    "fileslist = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "val_performance, train_time = {}, {}\n",
    "FILESNUMBER = 10\n",
    "LSTMNUMBER  = 3\n",
    "loss_method = 'mse'\n",
    "for i in range(FILESNUMBER):\n",
    "    # Getting data from csv file\n",
    "    filepath = join(path,fileslist[i])\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        [noInput, noOutput] = [int(x) for x in fp.readline().split(',')]\n",
    "    rdf = np.array(pd.read_csv(filepath, skiprows=1))\n",
    "\n",
    "    print('Step 1: Dividing the training and testing set with ratio 1:1 (50%).')\n",
    "    df_val, df_train = train_test_split(rdf,test_size=0.5)\n",
    "    print(df_train.shape, df_val.shape)\n",
    "\n",
    "    print('Step 2: Separating values and labels.')\n",
    "    x_train, y_train = seperateValues(df_train)\n",
    "    x_val, y_val = seperateValues(df_val)\n",
    "    print(\"+ Training set:   \", x_train.shape, y_train.shape, x_train.dtype)\n",
    "    print(\"+ Validating set: \", x_val.shape, y_val.shape, x_val.dtype)\n",
    "    \n",
    "    print('Step 3: LSTM modeling.')\n",
    "    lstm_model = tf.keras.Sequential()\n",
    "    lstm_model.add(\n",
    "      tf.keras.layers.LSTM(\n",
    "          units=128, \n",
    "          input_shape=[x_train.shape[1], x_train.shape[2]],\n",
    "          activation='tanh', recurrent_activation='sigmoid',\n",
    "          unroll =False,\n",
    "          use_bias=True,\n",
    "          recurrent_dropout=0,\n",
    "          return_sequences=False\n",
    "      )\n",
    "    )\n",
    "    lstm_model.add(tf.keras.layers.Dense(y_train.shape[1], activation='tanh'))\n",
    "    adam = tf.optimizers.Adam(learning_rate = 0.001, decay=1e-6)\n",
    "    lstm_model.compile(loss=loss_method, optimizer=adam, metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.51)])\n",
    "    val_performance[fileslist[i].split('.')[6]] = []\n",
    "    train_time[fileslist[i].split('.')[6]] = []\n",
    "    for lstm_no in range(LSTMNUMBER):\n",
    "        strt_time = datetime.datetime.now() \n",
    "        lstm_model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=8,\n",
    "            batch_size=1,\n",
    "            verbose=0,\n",
    "            validation_data=(x_val, y_val),\n",
    "            shuffle=True,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        curr_time = datetime.datetime.now()\n",
    "        display(lstm_model.summary())\n",
    "        timedelta = curr_time - strt_time\n",
    "        train_time[fileslist[i].split('.')[6]].append(timedelta.total_seconds())\n",
    "        val_performance[fileslist[i].split('.')[6]].append(lstm_model.evaluate(x_val, y_val))\n",
    "df = (pd.DataFrame.from_dict(val_performance, orient='index'))\n",
    "df[0] = df.apply(lambda x: round(x[0][1], 5),axis=1)\n",
    "df[1] = df.apply(lambda x: round(x[1][1], 5),axis=1)\n",
    "df[2] = df.apply(lambda x: round(x[2][1], 5),axis=1)\n",
    "time_df = pd.DataFrame.from_dict(train_time, orient='index').rename(columns = {0: 'Training_Time'})\n",
    "time_df['Training_Time'] = time_df.apply(lambda x: round(sum(x) / len(x), 5), axis=1)\n",
    "df = pd.concat([df, time_df], axis=1)\n",
    "df = df.rename(columns={0: '1st_run', 1: '2nd_run', 2: '3rd_run'})\n",
    "df.to_csv('./Results/{}_10datasets.csv'.format(loss_method), index=True, index_label='Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bdc1b923-8209-4120-a719-375abcd08ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 3, 4, 0]\n",
    "x = sum(x) / len(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468c558-547f-4cbb-bfb0-9f665cebdf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py385_gpu",
   "language": "python",
   "name": "py385_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
