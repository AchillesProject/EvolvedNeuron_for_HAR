{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014c1834-2e8b-4ef0-b778-ad180d274bef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D, GlobalAveragePooling2D, Flatten, Dropout, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorboard\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "\n",
    "from functools import partial\n",
    "from matplotlib import rc, style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import pandas as pd #pd.plotting.register_matplotlib_converters\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import sys, os, math, time, datetime\n",
    "\n",
    "\n",
    "# reduce number of threads\n",
    "# os.environ['TF_NUM_INTEROP_THREADS'] = '1' \n",
    "# os.environ['TF_NUM_INTRAOP_THREADS'] = '1' \n",
    "\n",
    "# disable GPU and anable MKL OneDNN\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "os.environ['DNNL_VERBOSE'] = '0'\n",
    "\n",
    "style.use(\"seaborn\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale = 1)\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "LOOP_NUMBER=3\n",
    "\n",
    "def shifting(bitlist):\n",
    "    out = 0\n",
    "    for bit in bitlist:\n",
    "        out = (out << 1) | bit\n",
    "    return out\n",
    "\n",
    "def fromBit( b ) :\n",
    "    if b == 0.0 :\n",
    "        return -0.9\n",
    "    return 0.9\n",
    "\n",
    "def isCorrect( target, actual ) :\n",
    "    if target < 0.0 :\n",
    "        y1 = False\n",
    "    else :\n",
    "        y1 = True\n",
    "    if actual < 0.0 :\n",
    "        y2 = False\n",
    "    else :\n",
    "        y2 = True\n",
    "    return y1 == y2\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edbb05b-4069-4960-a935-19af643592c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Starting with ./results/mse_07102021_ES/mse_3_5_30_128_9_2.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'./Version9.128timesteps/seqnetdata.ni=3.no=5.mc=30.numTimeSteps128.version9.2.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Dividing the training and testing set with ratio 1:1 (50%).\n",
      "(5000, 1024) (4999, 1024)\n",
      "Step 2: Separating values and labels.\n",
      "+ Training set:    (5000, 128, 3) (5000, 5) float32\n",
      "+ Validation set:  (4999, 128, 3) (4999, 5) float32\n",
      "Train on 5000 samples, validate on 4999 samples\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d9ce7ed8bcdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mstrt_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         lstm_model.fit(\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     return fit_loop(\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py385_gpu/lib/python3.8/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m   \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_load_initial_epoch_from_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "results_dir = \"./results/mse_07102021_ES/\"\n",
    "results_list = os.listdir(results_dir)\n",
    "\n",
    "for results_item in results_list:\n",
    "    resultpath = results_dir + results_item\n",
    "    display(f'Starting with {resultpath}')\n",
    "    result = pd.read_csv(resultpath, index_col=0)\n",
    "    dataset_no = result.loc['dataset_no'].values[0].split('_')\n",
    "    dataset_name = f'seqnetdata.ni={dataset_no[1]}.no={dataset_no[2]}.mc={dataset_no[3]}.numTimeSteps{dataset_no[4]}.version{dataset_no[5]}.{dataset_no[6]}.csv'\n",
    "    af_LSTM = result.loc['af_LSTM'].values[0]\n",
    "    raf_LSTM = result.loc['raf_LSTM'].values[0]\n",
    "    af_dense = result.loc['af_dense'].values[0]\n",
    "    optimizer_dense = result.loc['optimizer'].values[0]\n",
    "    learningrate = float(result.loc['learning_rate'].values[0])\n",
    "    epoch_no = int(result.loc['tuner/epochs'].values[0])\n",
    "\n",
    "    datapath = f'./Version9.128timesteps/{dataset_name}'\n",
    "    display(datapath)\n",
    "    with open(datapath, \"r\") as fp:\n",
    "        [noInput, noOutput] = [int(x) for x in fp.readline().split(',')]\n",
    "    rdf = np.array(pd.read_csv(datapath, skiprows=1))\n",
    "\n",
    "    print('Step 1: Dividing the training and testing set with ratio 1:1 (50%).')\n",
    "    df_val, df_train = train_test_split(rdf,test_size=0.5)\n",
    "    print(df_train.shape, df_val.shape)\n",
    "\n",
    "    print('Step 2: Separating values and labels.')\n",
    "    # Training set\n",
    "    x_train, y_train, x_val, y_val = None, None, None, None\n",
    "    for i in range(df_train.shape[0]):\n",
    "        df_train_i = df_train[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "        x_train_i, y_train_i = df_train_i[:, 0:noInput], df_train_i[-1, noInput:]\n",
    "        x_train = x_train_i[np.newaxis,:,:] if x_train is None else np.append(x_train, x_train_i[np.newaxis,:,:], axis=0)\n",
    "        y_train = y_train_i.reshape(1, -1) if y_train is None else np.append(y_train, y_train_i.reshape(1, -1), axis=0)\n",
    "    print(\"+ Training set:   \", x_train.shape, y_train.shape, x_train.dtype)\n",
    "\n",
    "    # Validation set\n",
    "    x_test, y_test = None, None\n",
    "    for i in range(df_val.shape[0]):\n",
    "        df_val_i = df_val[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "        x_val_i, y_val_i = df_val_i[:, 0:noInput], df_val_i[-1, noInput:]\n",
    "        x_val = x_val_i[np.newaxis,:,:] if x_val is None else np.append(x_val, x_val_i[np.newaxis,:,:], axis=0)\n",
    "        y_val = y_val_i.reshape(1,-1) if y_val is None else np.append(y_val, y_val_i.reshape(1,-1), axis=0)\n",
    "    print(\"+ Validation set: \", x_val.shape, y_val.shape, x_val.dtype)\n",
    "\n",
    "    for i in range( x_train.shape[ 0 ] ) :\n",
    "        for j in range( x_train.shape[ 1 ] ) :\n",
    "            for k in range( x_train.shape[ 2 ] ) :\n",
    "                x_train[ i, j, k ] = fromBit( x_train[ i, j, k ] )\n",
    "\n",
    "    for i in range( y_train.shape[ 0 ] ) :\n",
    "        for j in range( y_train.shape[ 1 ] ) :\n",
    "            y_train[ i, j ] = fromBit( y_train[ i, j ] )\n",
    "\n",
    "    for i in range( x_val.shape[ 0 ] ) :\n",
    "        for j in range( x_val.shape[ 1 ] ) :\n",
    "            for k in range( x_val.shape[ 2 ] ) :\n",
    "                x_val[ i, j, k ] = fromBit( x_val[ i, j, k ] )\n",
    "\n",
    "    for i in range( y_val.shape[ 0 ] ) :\n",
    "        for j in range( y_val.shape[ 1 ] ) :\n",
    "            y_val[ i, j ] = fromBit( y_val[ i, j ] )\n",
    "\n",
    "    lstm_model = tf.keras.Sequential()\n",
    "    lstm_model.add(\n",
    "      tf.keras.layers.LSTM(\n",
    "          units=8, \n",
    "          input_shape=[x_train.shape[1], x_train.shape[2]],\n",
    "          activation=af_LSTM, recurrent_activation=raf_LSTM,\n",
    "          unroll =False,\n",
    "          use_bias=True,\n",
    "          recurrent_dropout=0,\n",
    "          return_sequences=False\n",
    "      )\n",
    "    )\n",
    "\n",
    "    lstm_model.add(tf.keras.layers.Dense(y_train.shape[1], activation=af_dense))\n",
    "    if(optimizer_dense == 'adam'):\n",
    "        lstm_model.compile(loss='mse', optimizer=Adam(learning_rate = learningrate, decay=0), metrics=['mse'])\n",
    "    else:\n",
    "        lstm_model.compile(loss='mse', optimizer=SGD(learning_rate = learningrate), metrics=['mse'])\n",
    "    \n",
    "    for loop in range(LOOP_NUMBER):\n",
    "        strt_time = datetime.datetime.now() \n",
    "        \n",
    "        lstm_model.fit(\n",
    "            x_train, y_train, \n",
    "            batch_size=1,\n",
    "            verbose=1, # Suppress chatty output; use Tensorboard instead\n",
    "            epochs=epoch_no,\n",
    "            validation_data=(x_val, y_val),\n",
    "            shuffle=True,\n",
    "            callbacks=[tf.keras.callbacks.TerminateOnNaN()],\n",
    "        )\n",
    "        \n",
    "        curr_time = datetime.datetime.now()\n",
    "        timedelta = curr_time - strt_time\n",
    "        dnn_train_time = timedelta.total_seconds()\n",
    "        val_performance = lstm_model.evaluate(x_val, y_val)\n",
    "\n",
    "        display(val_performance)\n",
    "        y_pred = lstm_model.predict(x_val, verbose=1)\n",
    "\n",
    "        count = 0\n",
    "        numCorrect = 0\n",
    "        for i in range( y_pred.shape[ 0 ] ) :\n",
    "             for j in range( y_pred.shape[ 1 ] ) :\n",
    "                count += 1\n",
    "                if isCorrect( y_val[ i, j ], y_pred[ i, j ] ) :\n",
    "                    numCorrect += 1\n",
    "\n",
    "        print( f'Prediction_Accuracy_{loop} = {round(numCorrect / count,5)}' )\n",
    "        result.loc[f'val_acc_{loop}'] = round(val_performance[1], 5)\n",
    "        result.loc[f'pred_acc_{loop}'] = round(numCorrect / count, 5)\n",
    "#     result.to_csv(resultpath, index=True)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6ac56-cd79-40db-b967-72f338a6a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"./results/mse_07102021_ES/\"\n",
    "results_list = os.listdir(results_dir)\n",
    "\n",
    "for results_item in results_list:\n",
    "    resultpath = results_dir + results_item\n",
    "    display(f'Starting with {resultpath}')\n",
    "    result = pd.read_csv(resultpath, index_col=0)\n",
    "    dataset_no = result.loc['dataset_no'].values[0].split('_')\n",
    "    dataset_name = f'seqnetdata.ni={dataset_no[1]}.no={dataset_no[2]}.mc={dataset_no[3]}.numTimeSteps{dataset_no[4]}.version{dataset_no[5]}.{dataset_no[6]}.csv'\n",
    "    af_LSTM = result.loc['af_LSTM'].values[0]\n",
    "    raf_LSTM = result.loc['raf_LSTM'].values[0]\n",
    "    af_dense = result.loc['af_dense'].values[0]\n",
    "    optimizer_dense = result.loc['optimizer'].values[0]\n",
    "    learningrate = float(result.loc['learning_rate'].values[0])\n",
    "    epoch_no = float(result.loc['tuner/epochs'].values[0])\n",
    "\n",
    "    datapath = f'./Version9.128timesteps/{dataset_name}'\n",
    "    with open(datapath, \"r\") as fp:\n",
    "        [noInput, noOutput] = [int(x) for x in fp.readline().split(',')]\n",
    "    rdf = np.array(pd.read_csv(datapath, skiprows=1))\n",
    "\n",
    "    print('Step 1: Dividing the training and testing set with ratio 1:1 (50%).')\n",
    "    df_val, df_train = train_test_split(rdf,test_size=0.5)\n",
    "    print(df_train.shape, df_val.shape)\n",
    "\n",
    "    print('Step 2: Separating values and labels.')\n",
    "    # Training set\n",
    "    x_train, y_train, x_val, y_val = None, None, None, None\n",
    "    for i in range(df_train.shape[0]):\n",
    "        df_train_i = df_train[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "        x_train_i, y_train_i = df_train_i[:, 0:noInput], df_train_i[-1, noInput:]\n",
    "        x_train = x_train_i[np.newaxis,:,:] if x_train is None else np.append(x_train, x_train_i[np.newaxis,:,:], axis=0)\n",
    "        y_train = y_train_i.reshape(1, -1) if y_train is None else np.append(y_train, y_train_i.reshape(1, -1), axis=0)\n",
    "    print(\"+ Training set:   \", x_train.shape, y_train.shape, x_train.dtype)\n",
    "\n",
    "    # Validation set\n",
    "    x_test, y_test = None, None\n",
    "    for i in range(df_val.shape[0]):\n",
    "        df_val_i = df_val[i].reshape(-1, noInput+noOutput).astype('float32')\n",
    "        x_val_i, y_val_i = df_val_i[:, 0:noInput], df_val_i[-1, noInput:]\n",
    "        x_val = x_val_i[np.newaxis,:,:] if x_val is None else np.append(x_val, x_val_i[np.newaxis,:,:], axis=0)\n",
    "        y_val = y_val_i.reshape(1,-1) if y_val is None else np.append(y_val, y_val_i.reshape(1,-1), axis=0)\n",
    "    print(\"+ Validation set: \", x_val.shape, y_val.shape, x_val.dtype)\n",
    "\n",
    "    for i in range( x_train.shape[ 0 ] ) :\n",
    "        for j in range( x_train.shape[ 1 ] ) :\n",
    "            for k in range( x_train.shape[ 2 ] ) :\n",
    "                x_train[ i, j, k ] = fromBit( x_train[ i, j, k ] )\n",
    "\n",
    "    for i in range( y_train.shape[ 0 ] ) :\n",
    "        for j in range( y_train.shape[ 1 ] ) :\n",
    "            y_train[ i, j ] = fromBit( y_train[ i, j ] )\n",
    "\n",
    "    for i in range( x_val.shape[ 0 ] ) :\n",
    "        for j in range( x_val.shape[ 1 ] ) :\n",
    "            for k in range( x_val.shape[ 2 ] ) :\n",
    "                x_val[ i, j, k ] = fromBit( x_val[ i, j, k ] )\n",
    "\n",
    "    for i in range( y_val.shape[ 0 ] ) :\n",
    "        for j in range( y_val.shape[ 1 ] ) :\n",
    "            y_val[ i, j ] = fromBit( y_val[ i, j ] )\n",
    "\n",
    "    lstm_model = tf.keras.Sequential()\n",
    "    lstm_model.add(\n",
    "      tf.keras.layers.LSTM(\n",
    "          units=8, \n",
    "          input_shape=[x_train.shape[1], x_train.shape[2]],\n",
    "          activation=af_LSTM, recurrent_activation=raf_LSTM,\n",
    "          unroll =False,\n",
    "          use_bias=True,\n",
    "          recurrent_dropout=0,\n",
    "          return_sequences=False\n",
    "      )\n",
    "    )\n",
    "\n",
    "    lstm_model.add(tf.keras.layers.Dense(y_train.shape[1], activation=af_dense))\n",
    "    if(optimizer_dense == 'adam'):\n",
    "        lstm_model.compile(loss='mse', optimizer=Adam(learning_rate = learningrate, decay=0), metrics='mse')\n",
    "    else:\n",
    "        lstm_model.compile(loss='mse', optimizer=SGD(learning_rate = learningrate), metrics='mse')\n",
    "    \n",
    "    for loop in range(LOOP_NUMBER):\n",
    "        strt_time = datetime.datetime.now() \n",
    "        \n",
    "        lstm_model.fit(\n",
    "            x_train, y_train, \n",
    "            batch_size=1,\n",
    "            verbose=1, # Suppress chatty output; use Tensorboard instead\n",
    "            epochs=epoch_no,\n",
    "            validation_data=(x_val, y_val),\n",
    "            shuffle=True,\n",
    "            callbacks=[tf.keras.callbacks.TerminateOnNaN()],\n",
    "        )\n",
    "        \n",
    "        curr_time = datetime.datetime.now()\n",
    "        timedelta = curr_time - strt_time\n",
    "        dnn_train_time = timedelta.total_seconds()\n",
    "        val_performance = lstm_model.evaluate(x_val, y_val)\n",
    "\n",
    "        display(val_performance)\n",
    "        y_pred = lstm_model.predict(x_val, verbose=1)\n",
    "\n",
    "        count = 0\n",
    "        numCorrect = 0\n",
    "        for i in range( y_pred.shape[ 0 ] ) :\n",
    "             for j in range( y_pred.shape[ 1 ] ) :\n",
    "                count += 1\n",
    "                if isCorrect( y_val[ i, j ], y_pred[ i, j ] ) :\n",
    "                    numCorrect += 1\n",
    "\n",
    "        print( f'Prediction_Accuracy_{loop} = {round(numCorrect / count,5)}' )\n",
    "        result.loc[f'val_acc_{loop}'] = round(val_performance[1], 5)\n",
    "        result.loc[f'pred_acc_{loop}'] = round(numCorrect / count, 5)\n",
    "    result.to_csv(resultpath, index=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0d509-5938-4893-b4c9-e84a4a717a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py385_gpu",
   "language": "python",
   "name": "py385_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
