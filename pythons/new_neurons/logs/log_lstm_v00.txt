2022-06-03 17:09:18.555907: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
tf:  2.8.0
/home/chau/workingdir/tf_implementations/bash_scripts
{'batchSize': 4.0, 'numTrainingSteps': 320000.0, 'beta1': 0.974833, 'beta2': 0.99689, 'epsilon': 0.00388, 'decayDurationFactor': 0.979079, 'initialLearningRate': 0.002798, 'learningRateDecay': 0.001025, 'glorotScaleFactor': 0.1, 'orthogonalScaleFactor': 0.1, 'testSize': 0.5, 'noUnits': 81, 'timestep': 40}
Step 1: Dividing the training and testing set with ratio 1:1 (50%).
float64
Epoch 1/23
Traceback (most recent call last):
  File "../pythons/new_neurons/run/lstm_v00.py", line 142, in <module>
    model_history = model.fit(
  File "/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py", line 1147, in autograph_handler
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 1021, in train_function  *
        return step_function(self, iterator)
    File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 1010, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 1000, in run_step  **
        outputs = model.train_step(data)
    File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 863, in train_step
        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py", line 532, in minimize
        return self.apply_gradients(grads_and_vars, name=name)
    File "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py", line 665, in apply_gradients
        apply_state = self._prepare(var_list)
    File "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py", line 944, in _prepare
        self._prepare_local(var_device, var_dtype, apply_state)
    File "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py", line 125, in _prepare_local
        super(Adam, self)._prepare_local(var_device, var_dtype, apply_state)
    File "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py", line 950, in _prepare_local
        lr_t = tf.identity(self._decayed_lr(var_dtype))
    File "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py", line 1008, in _decayed_lr
        lr_t = tf.cast(lr_t(local_step), var_dtype)
    File "../pythons/new_neurons/run/lstm_v00.py", line 86, in __call__
        self.lr = tf.cond(self.step > self.T,

    TypeError: Input 'y' of 'Less' Op has type float64 that does not match type float32 of argument 'x'.

