{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a296d2b1",
   "metadata": {},
   "source": [
    "## Merging results of different networks platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6a7fb-fff1-4c05-8782-faf9c4179cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "path = \"./results/0_cpp/5_bigsets/\"\n",
    "fileslist = [f for f in sorted(os.listdir(path)) if os.path.isfile(os.path.join(path, f))]\n",
    "results_dir_o = \"./results/merge_results_5bigdatasets.csv\"\n",
    "\n",
    "def sprasingDataC(dir_i, dir_o, column_name):    \n",
    "    with open(dir_i) as f:\n",
    "        lines = [[line.strip('\\n').split(' ')[index] for index in [0, 4, 6]] for line in f.readlines()]\n",
    "        \n",
    "    data_count, run_count, seed = 0, 0, 0\n",
    "    result = {}\n",
    "    result['summary'] = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if data_count == 0:\n",
    "            seed = int(line[0].split(':')[0].split('.')[-1].split('=')[-1])\n",
    "            result[seed] = {}\n",
    "        filename  = line[1].split('/')[-1]\n",
    "        no        = int(filename.split('.')[2].split('=')[-1])\n",
    "        error_no  = float(line[2])\n",
    "        result[seed][filename]  = round((1. - error_no/(no*4999))*100, 2)\n",
    "        if run_count == 0:\n",
    "            result['summary'][filename] = [result[seed][filename]]\n",
    "        else:\n",
    "            result['summary'][filename].append(result[seed][filename])\n",
    "        run_count = run_count + 1 if data_count == 4 else run_count\n",
    "        data_count = data_count + 1 if data_count < 4 else 0\n",
    "\n",
    "    for k, v in result['summary'].items():\n",
    "        result['summary'][k] = round(sum(result['summary'][k]) / len(result['summary'][k]), 2)\n",
    "\n",
    "    return pd.DataFrame.from_dict(result['summary'], orient='index', columns=[column_name])\n",
    "\n",
    "result_c = pd.DataFrame()\n",
    "for file in fileslist:\n",
    "    result_c = pd.concat([result_c, sprasingDataC(path+file, results_dir_o, file.split('.')[1])], axis=1)\n",
    "\n",
    "result_c.to_csv(results_dir_o, index=True, index_label='dataset', mode='a')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49af41c-944e-4f26-b315-ec99b2cbaad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaut\\Anaconda3\\envs\\master_thesis\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "path = \"./results/0_cpp/5_bigsets/\"\n",
    "fileslist = [f for f in sorted(os.listdir(path)) if os.path.isfile(os.path.join(path, f))]\n",
    "results_dir_o = \"./results/merge_results_5bigdatasets.csv\"\n",
    "\n",
    "def sprasingDataC(dir_i, dir_o, column_name):    \n",
    "    with open(dir_i) as f:\n",
    "        lines = [[line.strip('\\n').split(' ')[index] for index in [0, 2, 4]] for line in f.readlines()]\n",
    "        \n",
    "    data_count, run_count, seed = 0, 0, 0\n",
    "    result = {}\n",
    "    result['summary'] = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if data_count == 0:\n",
    "            seed = int(line[0].split(':')[0].split('=')[-1])\n",
    "            result[seed] = {}\n",
    "        filename  = line[1].split('/')[-1]\n",
    "        no        = int(filename.split('.')[2].split('=')[-1])\n",
    "        error_no  = float(line[2])\n",
    "        result[seed][filename]  = round(error_no*100, 2)\n",
    "        if run_count == 0:\n",
    "            result['summary'][filename] = [result[seed][filename]]\n",
    "        else:\n",
    "            result['summary'][filename].append(result[seed][filename])\n",
    "        run_count = run_count + 1 if data_count == 4 else run_count\n",
    "        data_count = data_count + 1 if data_count < 4 else 0\n",
    "\n",
    "    for k, v in result['summary'].items():\n",
    "        result['summary'][k] = round(sum(result['summary'][k]) / len(result['summary'][k]), 2)\n",
    "\n",
    "    return pd.DataFrame.from_dict(result['summary'], orient='index', columns=[column_name])\n",
    "\n",
    "# for file in fileslist:\n",
    "readfile = pd.read_csv(results_dir_o, index_col='dataset',sep='[;,]', engine='python')\n",
    "readfile.index.name = None\n",
    "pd.concat([readfile, sprasingDataC(path+\"5_bigsets.olstm_wtLRS_nES_c.txt\", results_dir_o, \"5_bigsets.olstm_wtLRS_nES_c.txt\".split('.')[1])], axis=1).to_csv(results_dir_o, index=True, index_label='dataset', mode='w') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356878d2-d9c8-4fe0-9eb2-7f43350cf27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
