{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab4242e-5813-413c-85b9-e9371a7a3808",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert\" style=\"background-color:#29C5F6; color:white; padding:0px 10px; border-radius:5px;\">\n",
    "    <h1 style='margin:15px 15px; color:#000000; font-size:32px'><b>Data Generation (Processing)</b></h1>\n",
    "        <h2 style='margin:15px 15px; color:#000000; font-size:24px'>Human Activity Recognition Problem</h2>\n",
    "            <div style='color:#000000'>\n",
    "                <ul>\n",
    "                  <li>WISDM - WIreless Sensor Data Mining</li>\n",
    "                  <li>UCI HAR - Human Activity Recognition using Smartphones at UCI</li>\n",
    "                  <li><b>MotionSense</b></li>\n",
    "                </ul>\n",
    "            </div>\n",
    "</div>\n",
    "\n",
    "The work is under the **\"Master Thesis\"** by **Chau Tran** with the supervision from **Prof. Roland Olsson**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0061ca-8cff-4c77-8ddd-c7a5ce0da907",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert\" style=\"background-color:#29C5F6; border-radius:5px; padding:0px 10px; \"><h3 style='margin:15px 15px'>6_3. MotionSense</h3></div>\n",
    "<div>\n",
    "    <p>\n",
    "        Source1: <a href=\"url\">https://github.com/mmalekzadeh/motion-sense</a> <br>\n",
    "        Source2: <a href=\"url\">https://www.kaggle.com/malekzadeh/motionsense-dataset</a> <br>\n",
    "    </p>\n",
    "    <p> Folder's format: </p>\n",
    "    <ul>\n",
    "        <li>A_DeviceMotion_data:  All accelerometer and gyroscope data for all 15 trials</li>\n",
    "        <li>B_Accelerometer_data: Only accelerometer data for all 15 trials</li>\n",
    "        <li>C_Gyroscope_data:     Only gyroscope for all 15 trials</li>\n",
    "    </ul>\n",
    "    <p>\n",
    "        Raw's format: <b>[user],[activity],[x-acceleration],[y-accel],[z-accel]</b> <br>\n",
    "        Number of samples for non-hand-oriented activities (6 activities): <b>???</b><br>\n",
    "    </p> \n",
    "    <ul>\n",
    "      <li>Walking - wlk:      ???</li>\n",
    "      <li>Jogging - jog:      ???</li>\n",
    "      <li>UpStairs - ups:     ???</li>\n",
    "      <li>Sitting - sit:      ???</li>\n",
    "      <li>Standing - std:     ???</li>\n",
    "      <li>DownStairs - dws:   ???</li>\n",
    "    </ul> \n",
    "    <p>Fields:<br></p>\n",
    "    <ul>\n",
    "      <li>user: 1..24</li>\n",
    "      <li>activity: {Walking, Jogging, Sitting, Standing, Upstairs, <b>Downstairs</b>}</li>\n",
    "      <li>timestamp: microsecond (Unix Time)</li>\n",
    "      <li>x-accel: floating-point values between -20 .. 20</li>\n",
    "      <li>y-accel: floating-point values between -20 .. 20</li>\n",
    "      <li>z-accel: floating-point values between -20 .. 20</li>\n",
    "    </ul>\n",
    "    <p> The acceleration in the x direction as measured by the android phone's accelerometer. A value of 10 = 1g = 9.81 m/s^2, and 0 = no acceleration. The acceleration recorded includes gravitational acceleration toward the center of the Earth, so that when the phone is at rest on a flat surface the vertical axis will register +-10. <br></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49212a66-f1ba-4861-9424-6a975c5311c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 40\n",
      "(716, 90, 12) (716, 90, 6) (716, 1620)\n",
      "(716, 90, 12) (716, 90, 6) (716, 1620)\n",
      "(1430, 90, 12) (1430, 90, 6) (1430, 1620)\n",
      "60 30\n",
      "(954, 60, 12) (954, 60, 6) (954, 1080)\n",
      "(954, 60, 12) (954, 60, 6) (954, 1080)\n",
      "(1907, 60, 12) (1907, 60, 6) (1907, 1080)\n",
      "50 20\n",
      "(1430, 50, 12) (1430, 50, 6) (1430, 900)\n",
      "(1430, 50, 12) (1430, 50, 6) (1430, 900)\n",
      "(2859, 50, 12) (2859, 50, 6) (2859, 900)\n",
      "40 20\n",
      "(1430, 40, 12) (1430, 40, 6) (1430, 720)\n",
      "(1430, 40, 12) (1430, 40, 6) (1430, 720)\n",
      "(2859, 40, 12) (2859, 40, 6) (2859, 720)\n",
      "90 90\n",
      "(320, 90, 12) (320, 90, 6) (320, 1620)\n",
      "(320, 90, 12) (320, 90, 6) (320, 1620)\n",
      "(638, 90, 12) (638, 90, 6) (638, 1620)\n",
      "60 60\n",
      "(478, 60, 12) (478, 60, 6) (478, 1080)\n",
      "(478, 60, 12) (478, 60, 6) (478, 1080)\n",
      "(954, 60, 12) (954, 60, 6) (954, 1080)\n",
      "50 50\n",
      "(574, 50, 12) (574, 50, 6) (574, 900)\n",
      "(574, 50, 12) (574, 50, 6) (574, 900)\n",
      "(1145, 50, 12) (1145, 50, 6) (1145, 900)\n",
      "40 40\n",
      "(716, 40, 12) (716, 40, 6) (716, 720)\n",
      "(716, 40, 12) (716, 40, 6) (716, 720)\n",
      "(1430, 40, 12) (1430, 40, 6) (1430, 720)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "import sys, os\n",
    "\n",
    "TIME_STEPS_arr = [90, 60, 50, 40]\n",
    "isSTEPS_arr = [True, False]\n",
    "SPLIT = 0.5\n",
    "NO_IN, NO_OUT = 12, 6\n",
    "\n",
    "def divideData_perUser(data, per=0.5):\n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "    X_df = pd.DataFrame()\n",
    "    for user in np.unique(data['user']):\n",
    "        dataPerUser = data[data['user']==user]\n",
    "        for tag in np.unique(dataPerUser['activity']):\n",
    "            dataPerActivity = dataPerUser[dataPerUser['activity']==tag]\n",
    "            n = len(dataPerActivity)\n",
    "            train_df = train_df.append(dataPerActivity[0:int(n*per)])\n",
    "            val_df = val_df.append(dataPerActivity[int(n*per):int(n)])\n",
    "            X_df = X_df.append(dataPerActivity)        \n",
    "    return X_df, train_df, val_df\n",
    "\n",
    "# Utils functions for segmenting windows\n",
    "def windows(data,window_size,step):\n",
    "    start = 0\n",
    "    while start< data.count():\n",
    "        yield int(start), int(start + window_size)\n",
    "        start+= step\n",
    "def segment_signal(data, window_size = 90, step=40, columns=[]):\n",
    "    segments = np.empty((0,window_size,len(columns)))\n",
    "    labels= np.empty((0))\n",
    "    for user in np.unique(data['user']):\n",
    "        userdata = data[(data.user == user)]\n",
    "        for tag in np.unique(userdata['activity']):\n",
    "            sub_class_data = userdata[(userdata.activity == tag)]\n",
    "            for (start, end) in windows(pd.Series(sub_class_data.index.values),window_size,step):\n",
    "                if end > sub_class_data.shape[0] - 1:\n",
    "                    end = sub_class_data.shape[0]\n",
    "                    true_length = end - start\n",
    "                    remaining_data_length = window_size - true_length\n",
    "                    start -= remaining_data_length\n",
    "                if (sub_class_data[start:end].isnull().values.any()):\n",
    "                    print(sub_class_data[start:end].isnull().sum())\n",
    "                if(sub_class_data[start:end].shape[0] == window_size):\n",
    "                    segments = np.vstack([segments,np.dstack([sub_class_data[column][start:end] for column in columns])])\n",
    "                    labels = np.append(labels, tag)\n",
    "    return segments, labels.reshape(-1, 1)\n",
    "\n",
    "motionsense_path = '../../../../Datasets/6_har/2_MotionSense/1_data'\n",
    "motionsense_phone_path = f'{motionsense_path}/A_DeviceMotion_data'\n",
    "os.mkdir(f\"{motionsense_path}/A_DeviceMotion_data_processed/motionsense_w_overlap/\") if os.path.isdir(f\"{motionsense_path}/A_DeviceMotion_data_processed/motionsense_w_overlap/\") == False else None\n",
    "os.mkdir(f\"{motionsense_path}/A_DeviceMotion_data_processed/motionsense_wt_overlap/\") if os.path.isdir(f\"{motionsense_path}/A_DeviceMotion_data_processed/motionsense_wt_overlap/\") == False  else N\n",
    "\n",
    "motionsense_phone_data = pd.DataFrame()\n",
    "motionsense_phone_subpaths = os.listdir(motionsense_phone_path)\n",
    "for motionsense_phone_subpath in motionsense_phone_subpaths:\n",
    "    activity = motionsense_phone_subpath.split('_')[0]\n",
    "    for user_data_path in os.listdir(f'{motionsense_phone_path}/{motionsense_phone_subpath}'):\n",
    "        user_id = user_data_path.split('.')[0].split('_')[-1]\n",
    "        user_data = pd.read_csv(f'{motionsense_phone_path}/{motionsense_phone_subpath}/{user_data_path}', header=0, index_col=0)\n",
    "        user_data.insert(0, 'user', user_id)\n",
    "    user_data.insert(1, 'activity', activity)\n",
    "    motionsense_phone_data = motionsense_phone_data.append(user_data, ignore_index=True)\n",
    "\n",
    "motionsense_phone_data.dropna(axis=0, how='any', inplace=True)\n",
    "mapping_dict = {'wlk': 1,'jog': 2, 'sit': 3, 'std': 4, 'ups': 5, 'dws': 5, 'LyingDown': 6}\n",
    "motionsense_phone_data['activity'] = motionsense_phone_data.activity.map(mapping_dict)\n",
    "\n",
    "COLUMNS = list(motionsense_phone_data.columns)\n",
    "COLUMNS.remove('user')\n",
    "COLUMNS.remove('activity')\n",
    "X_df, train_df, val_df = divideData_perUser(motionsense_phone_data, SPLIT)\n",
    "\n",
    "for isSTEPS in isSTEPS_arr:\n",
    "    for TIME_STEPS in TIME_STEPS_arr:\n",
    "        STEP = int(round(TIME_STEPS/2,-1)) if isSTEPS else TIME_STEPS\n",
    "        print(TIME_STEPS, STEP)\n",
    "\n",
    "        X, y = segment_signal(X_df, window_size=TIME_STEPS, step=STEP,columns=COLUMNS)\n",
    "        X_train, y_train = segment_signal(train_df, window_size=TIME_STEPS, step=STEP,columns=COLUMNS)\n",
    "        X_val, y_val = segment_signal(val_df, window_size=TIME_STEPS, step=STEP,columns=COLUMNS)\n",
    "\n",
    "        enc = OneHotEncoder().fit(np.array(list(mapping_dict.values())).reshape(-1,1))\n",
    "        y_train = enc.transform(y_train).toarray()\n",
    "        y_val   = enc.transform(y_val).toarray()\n",
    "        y       = enc.transform(y).toarray()\n",
    "\n",
    "        y_train = np.tile(y_train, TIME_STEPS).reshape((y_train.shape[0], TIME_STEPS, y_train.shape[1]))\n",
    "        y_val   = np.tile(y_val, TIME_STEPS).reshape((y_val.shape[0], TIME_STEPS, y_val.shape[1]))\n",
    "        y       = np.tile(y, TIME_STEPS).reshape((y.shape[0], TIME_STEPS, y.shape[1]))\n",
    "\n",
    "        df_train = np.concatenate((X_train, y_train), axis=2).reshape((X_train.shape[0], -1))\n",
    "        df_val = np.concatenate((X_val, y_val), axis=2).reshape((X_val.shape[0], -1))\n",
    "        df = np.concatenate((X,y), axis=2).reshape((X.shape[0], -1))\n",
    "        \n",
    "        print(X_train.shape, y_train.shape, df_train.shape)\n",
    "        print(X_val.shape, y_val.shape, df_val.shape)\n",
    "        print(X.shape, y.shape, df.shape)\n",
    "\n",
    "        motionsense_phone_result_path = f\"{motionsense_path}/A_DeviceMotion_data_processed/motionsense_wt_overlap/\" if TIME_STEPS==STEP else f\"{motionsense_path}/A_DeviceMotion_data_processed/motionsense_w_overlap/\"\n",
    "        \n",
    "        with open(fr\"{motionsense_phone_result_path}/motionsense.ni={NO_IN}.no={NO_OUT}.ts={TIME_STEPS}.os={STEP}.spit={0}.all.csv\",'w') as csvfile:\n",
    "            np.savetxt(csvfile, np.array([[NO_IN, NO_OUT]]),fmt='%d', delimiter=\",\")\n",
    "        with open(fr\"{motionsense_phone_result_path}/motionsense.ni={NO_IN}.no={NO_OUT}.ts={TIME_STEPS}.os={STEP}.spit={0}.all.csv\",'a') as csvfile:\n",
    "            np.savetxt(csvfile, df, fmt='%.4f', delimiter=\",\")\n",
    "\n",
    "        with open(fr\"{motionsense_phone_result_path}/motionsense.ni={NO_IN}.no={NO_OUT}.ts={TIME_STEPS}.os={STEP}.spit={int(SPLIT*100)}.train.csv\",'w') as csvfile:\n",
    "            np.savetxt(csvfile, np.array([[NO_IN, NO_OUT]]),fmt='%d', delimiter=\",\")\n",
    "        with open(fr\"{motionsense_phone_result_path}/ucihar.ni={NO_IN}.no={NO_OUT}.ts={TIME_STEPS}.os={STEP}.spit={int(SPLIT*100)}.train.csv\",'a') as csvfile:\n",
    "            np.savetxt(csvfile, df_train, fmt='%.4f', delimiter=\",\")\n",
    "\n",
    "        with open(fr\"{motionsense_phone_result_path}/motionsense.ni={NO_IN}.no={NO_OUT}.ts={TIME_STEPS}.os={STEP}.spit={int(SPLIT*100)}.val.csv\",'w') as csvfile:\n",
    "            np.savetxt(csvfile, np.array([[NO_IN, NO_OUT]]),fmt='%d', delimiter=\",\")\n",
    "        with open(fr\"{motionsense_phone_result_path}/motionsense.ni={NO_IN}.no={NO_OUT}.ts={TIME_STEPS}.os={STEP}.spit={int(SPLIT*100)}.val.csv\",'a') as csvfile:\n",
    "            np.savetxt(csvfile, df_val, fmt='%.4f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e79be-2fc8-4218-b3b2-958c17bb6a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
